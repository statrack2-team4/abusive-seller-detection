# 어뷰징 판매자 탐지 시스템 발표 대본

**발표 시간:** 약 15-20분
**대상:** 기술/비즈니스 혼합 청중

---

## 1. 오프닝 (1분)

> 안녕하세요. 오늘 발표할 주제는 **"머신러닝 기반 어뷰징 판매자 탐지 시스템"**입니다.
>
> 여러분, 온라인 쇼핑을 하다가 이런 경험 있으신가요?
>
> 리뷰가 수백 개인데 다 비슷한 내용이거나, 배송비가 상품 가격보다 비싸거나, 문의를 해도 답변이 없는 판매자를 만난 경험이요.
>
> 이런 판매자들은 단순히 불친절한 게 아닙니다. **시스템을 교묘하게 악용하는 어뷰징 판매자**일 가능성이 높습니다.
>
> 오늘 저는 이런 어뷰징 판매자를 **머신러닝으로 자동 탐지**하는 시스템을 소개해 드리겠습니다.

---

## 2. 문제 정의 (2분)

### 2.1 어뷰징 판매자란?

> 먼저 어뷰징 판매자가 무엇인지 정의하겠습니다.
>
> 어뷰징 판매자는 **플랫폼의 허점을 이용해 부당한 이익을 취하면서도, 표면적으로는 정상 판매자처럼 보이는** 판매자입니다.
>
> 대표적인 유형으로는:
> - **위너 시스템 악용**: 랭킹 알고리즘을 조작해 상위 노출
> - **옵션가 악용**: 미끼 가격으로 유인 후 비싼 옵션 판매
> - **가짜 리뷰 조작**: 자작 리뷰나 리뷰 구매로 평점 조작
> - **해외 직구 위장**: 품질 미보장 제품을 정품처럼 판매

### 2.2 왜 탐지가 어려운가?

> 단순 규칙으로 탐지하면 안 되나요?
>
> 문제는 어뷰징 판매자들이 **점점 정교해지고 있다**는 것입니다.
> - 평점 4.8 이하면 어뷰징? → 교묘하게 4.9를 유지합니다
> - 리뷰가 너무 많으면 의심? → 적당한 수준으로 조절합니다
>
> 결국 **단일 지표가 아닌 복합적인 패턴**을 봐야 합니다. 이것이 머신러닝이 필요한 이유입니다.

---

## 3. 데이터 수집 (2분)

### 3.1 데이터 소스

> 이 프로젝트에서는 쿠팡 마켓플레이스 데이터를 수집했습니다.
>
> | 데이터 | 수량 |
> |--------|------|
> | 판매자 | 401개 |
> | 상품 | 410개 |
> | 리뷰 | 8,238개 |
> | 문의 | 5,482개 |
>
> 수집 방법은 쿠팡 Open API와 웹 크롤링을 병행했고, 요청 간 30초 간격을 두어 서버 부하를 최소화했습니다.

### 3.2 라벨링 기준

> 중요한 건 **어떻게 어뷰징 판매자를 정의했는가**입니다.
>
> 저는 다음 6가지 휴리스틱 기준을 적용했습니다:
> 1. 상품 대비 리뷰 수가 비정상적으로 적거나 많음
> 2. 문의 응답률이 현저히 낮음
> 3. 상품 이미지/설명 품질이 조악함
> 4. 브랜드 스토어가 아닌 비전문 판매자
> 5. 가격이 극단적으로 저렴하거나 비쌈
> 6. 배송비 조작 (상품가 낮추고 배송비 높임)
>
> 최종적으로 **189명의 어뷰징 판매자**와 **212명의 정상 판매자**를 라벨링했습니다.
> 약 47:53 비율로 **거의 균형 잡힌 데이터셋**입니다.

---

## 4. 탐색적 데이터 분석 (2분)

### 4.1 주요 발견

> 데이터를 분석해보니 흥미로운 패턴이 보였습니다.
>
> **첫째, 리뷰 길이의 차이입니다.**
> - 정상 판매자: 평균 180자 이상의 상세 리뷰
> - 어뷰징 판매자: 평균 80자 미만의 짧은 리뷰
>
> **둘째, 문의 응답률입니다.**
> - 정상 판매자: 85% 이상 응답
> - 어뷰징 판매자: 40% 미만 응답
>
> **셋째, 리뷰 유사도입니다.**
> - 정상 판매자: 다양한 리뷰 내용
> - 어뷰징 판매자: 비슷한 문구가 반복 (복사-붙여넣기 의심)

### 4.2 핵심 인사이트

> 특히 주목할 점은, **단일 지표로는 구분이 안 된다**는 것입니다.
>
> 예를 들어 평점 4.9인 판매자가 어뷰징일 수도, 정상일 수도 있습니다.
> 하지만 "평점 4.9 + 리뷰 길이 짧음 + 응답률 낮음 + 리뷰 유사도 높음"이 조합되면, 어뷰징 확률이 급격히 올라갑니다.
>
> 이런 **복합 패턴을 학습**하는 것이 머신러닝의 역할입니다.

---

## 5. 피처 엔지니어링 (3분)

### 5.1 생성한 피처들

> 원본 데이터에서 총 **24개의 피처**를 엔지니어링했습니다.
>
> **상품 기반 피처 (11개)**
> ```
> - 가격 통계: 평균, 표준편차, 최소, 최대
> - 평점 통계: 평균, 표준편차
> - 배송 정보: 배송비, 배송일
> - 할인 정보: 평균 할인율, 최대 할인율
> ```
>
> **리뷰 패턴 피처 (6개)**
> ```
> - 실제 리뷰 수
> - 리뷰 평균 길이
> - 짧은 리뷰 비율 (30자 미만)
> - 5점 리뷰 비율
> - 리뷰 평균 평점
> - 리뷰 유사도 (TF-IDF 코사인 유사도)
> ```
>
> **문의 응대 피처 (6개)**
> ```
> - 문의 수
> - 응답률
> - 평균 응답 시간
> - 빠른 응답 비율 (24시간 이내)
> - 짧은 답변 비율 (20자 미만)
> - 평균 답변 길이
> ```

### 5.2 핵심 피처: 리뷰 유사도

> 특히 **리뷰 유사도**는 이 프로젝트의 핵심 피처입니다.
>
> 계산 방법을 간단히 설명드리면:
> 1. 한 판매자의 모든 리뷰 텍스트를 수집합니다
> 2. TF-IDF로 벡터화합니다 (상위 100개 단어)
> 3. 모든 리뷰 쌍의 코사인 유사도를 계산합니다
> 4. 평균을 구합니다
>
> 유사도가 1에 가까우면 **모든 리뷰가 거의 똑같다**는 의미입니다.
> 이는 자작 리뷰나 리뷰 구매의 강력한 신호입니다.

---

## 6. 모델 학습 (3분)

### 6.1 베이스라인 모델

> 먼저 여러 알고리즘으로 베이스라인을 잡았습니다.
>
> | 모델 | 테스트 정확도 | ROC-AUC |
> |------|---------------|---------|
> | Logistic Regression | 88.8% | 0.960 |
> | Random Forest | 90.6% | 0.965 |
> | Gradient Boosting | 89.1% | 0.971 |
> | SVM | 85.9% | 0.953 |
>
> Random Forest가 가장 좋은 성능을 보였지만, 문제가 있었습니다.
> **훈련 정확도가 100%**였습니다. 전형적인 **과적합** 신호죠.

### 6.2 과적합 방지

> 과적합을 해결하기 위해 여러 기법을 적용했습니다.
>
> **1. 5-Fold 교차검증**
> - 단일 테스트셋이 아닌 5번의 검증으로 안정성 확인
>
> **2. 피처 선택 (Feature Selection)**
> - SelectFromModel로 중요도 낮은 피처 제거
> - 24개 → 4개 핵심 피처로 압축해도 성능 유지
>
> **3. 하이퍼파라미터 튜닝**
> - max_depth: 10 → 3~5로 제한 (얕은 트리)
> - min_samples_split: 2 → 10~20으로 증가
> - max_features: 'sqrt' (피처 샘플링)
>
> **4. Early Stopping (Gradient Boosting)**
> - Validation loss가 10회 연속 개선 안되면 중단
>
> **5. Learning Curve 분석**
> - Train-Validation gap이 0.02 이내로 감소 → 과적합 해소

### 6.3 최종 모델 성능

> 튜닝 후 최종 성능입니다.
>
> | 메트릭 | 점수 |
> |--------|------|
> | 정확도 | 91.4% |
> | 정밀도 | 94.3% |
> | 재현율 | 86.8% |
> | F1-Score | 90.4% |
> | ROC-AUC | 0.970 |
>
> 5-Fold 교차검증에서도 F1 **91.85% ± 2%**로 안정적입니다.
> Train-Val gap도 **0.019**로 과적합이 해소되었습니다.

---

## 7. 모델 해석 - SHAP 분석 (2분)

### 7.1 피처 중요도

> 블랙박스 모델을 해석하기 위해 SHAP 분석을 수행했습니다.
>
> **Top 5 중요 피처:**
> 1. **satisfaction_score** (고객 만족도) - 가장 중요
> 2. **review_count** (리뷰 수)
> 3. **total_product_count** (상품 수)
> 4. **review_sum** (리뷰 합계)
> 5. **answer_rate** (문의 응답률)
>
> 흥미로운 점은, **가격이나 평점보다 행동 패턴**이 더 중요하다는 것입니다.

### 7.2 개별 예측 설명

> SHAP Waterfall 차트로 개별 예측을 설명할 수 있습니다.
>
> 예를 들어 "판매자 A"가 어뷰징으로 판정된 이유:
> - 기본 확률: 47% (전체 평균)
> - satisfaction_score 낮음: +15%
> - answer_rate 낮음: +12%
> - review_similarity 높음: +8%
> - **최종 확률: 82%** → 어뷰징 판정
>
> 이렇게 **왜 이 판매자가 어뷰징인지** 근거를 제시할 수 있습니다.

---

## 8. 오류 분석 (2분)

### 8.1 오분류 유형

> 완벽한 모델은 없습니다. 오분류 사례를 분석했습니다.
>
> 테스트셋 81건 중:
> - **정답**: 74건 (91.4%)
> - **False Positive**: 2건 (정상 → 어뷰징 오판)
> - **False Negative**: 5건 (어뷰징 → 정상 오판)

### 8.2 False Positive (억울한 판매자)

> 정상인데 어뷰징으로 오판된 2건을 살펴보면:
> - 소규모 신규 판매자
> - 아직 리뷰/문의가 충분히 쌓이지 않음
> - 낮은 활동량이 어뷰징 패턴과 유사하게 보임
>
> **개선 방향**: 신규 판매자는 별도 기준 적용 필요

### 8.3 False Negative (놓친 어뷰징)

> 어뷰징인데 탐지 못한 5건:
> - 정교하게 위장된 케이스
> - 리뷰 길이/응답률을 적절히 조절
> - 단순 패턴으로는 탐지 어려움
>
> **개선 방향**: 시계열 패턴, 리뷰 작성 시간 분포 등 추가 피처 필요

---

## 9. 비용-리스크 시뮬레이션 (2분)

### 9.1 비용 프레임워크

> 이 모델을 실제 적용하면 어떤 비용이 발생할까요?
>
> | 항목 | 비용 |
> |------|------|
> | False Negative (어뷰징 미탐지) | 2억원+ (피해 보상, 신뢰도 하락) |
> | False Positive (정상 오차단) | 1천만원+ (소송, 보상, 평판) |
> | 경고 시스템 운영 | 20만원/건 |

### 9.2 전략 비교

> 세 가지 전략을 시뮬레이션했습니다.
>
> **전략 A: 현행 유지 (수동 탐지)**
> - 대부분 어뷰징이 방치됨
> - 연간 피해: 수천억 원
>
> **전략 B: 강경 대응 (즉시 차단)**
> - 모델 신뢰도 70% 이상이면 즉시 차단
> - FP 비용 급증 (억울한 판매자)
>
> **전략 C: 단계적 대응 (권장)**
> - 70-90%: 경고 + 모니터링
> - 90% 이상: 심층 조사
> - 확인 후 조치
>
> 시뮬레이션 결과, **전략 C가 비용을 90% 절감**하면서도 리스크를 관리합니다.

---

## 10. 시스템 구현 (1분)

### 10.1 기술 스택

> 실제 서비스를 위해 다음과 같이 구현했습니다.
>
> - **데이터베이스**: Supabase (PostgreSQL)
> - **ML 파이프라인**: scikit-learn Pipeline
> - **웹 대시보드**: Streamlit
> - **시각화**: Plotly
> - **모델 해석**: SHAP
>
> 모델은 **80KB**로 경량화되어 실시간 추론이 가능합니다.

### 10.2 대시보드 기능

> Streamlit 대시보드에서는:
> - 전체 검증 결과 (정확도, Confusion Matrix, ROC Curve)
> - 개별 판매자 조회 (어뷰징 확률, 피처 상세)
> - 피처 중요도 시각화
>
> 를 실시간으로 확인할 수 있습니다.

---

## 11. 한계점 및 향후 계획 (1분)

### 11.1 현재 한계

> 솔직히 인정해야 할 한계가 있습니다.
>
> 1. **라벨링의 주관성**: 휴리스틱 기반이라 완벽하지 않음
> 2. **데이터 규모**: 401명은 대규모 서비스 기준 작음
> 3. **시계열 미반영**: 행동 변화 패턴을 못 봄
> 4. **이미지 미활용**: 상품 이미지 품질 분석 미포함

### 11.2 향후 개선 방향

> 향후 개선 계획입니다.
>
> 1. **시계열 피처 추가**: 리뷰 작성 시간 분포, 매출 급변 등
> 2. **네트워크 분석**: 연관 계정 탐지
> 3. **이미지 분석**: CNN으로 위조품 탐지
> 4. **반품/환불 데이터**: 구매 후 행동 패턴 추가

---

## 12. 결론 (1분)

> 정리하겠습니다.
>
> 이 프로젝트에서 저는:
>
> 1. **401명의 판매자 데이터**를 수집하고 라벨링했습니다
> 2. **24개의 피처**를 엔지니어링하여 행동 패턴을 포착했습니다
> 3. **91.4% 정확도의 Random Forest 모델**을 개발했습니다
> 4. **SHAP으로 모델을 해석**하여 투명성을 확보했습니다
> 5. **Streamlit 대시보드**로 실사용 가능한 시스템을 구현했습니다
>
> 핵심 메시지는, **단순 규칙이 아닌 복합 패턴 학습**이 어뷰징 탐지의 열쇠라는 것입니다.
>
> 질문 받겠습니다. 감사합니다.

---

## 예상 질문 및 답변

### Q1: 왜 딥러닝을 안 썼나요?

> 좋은 질문입니다. 두 가지 이유가 있습니다.
>
> 첫째, **데이터 규모**입니다. 401개 샘플로는 딥러닝이 과적합되기 쉽습니다.
>
> 둘째, **해석 가능성**입니다. 판매자를 차단할 때는 "왜"라는 근거가 필요합니다.
> Random Forest + SHAP 조합이 이 요구사항을 충족합니다.
>
> 물론 데이터가 수만 개로 늘어나면 딥러닝도 고려할 수 있습니다.

### Q2: 실제 서비스에 적용할 수 있나요?

> 현재 상태로도 **PoC (Proof of Concept)** 수준으로 적용 가능합니다.
>
> 다만 실 서비스 적용을 위해서는:
> - 더 많은 데이터로 재학습
> - A/B 테스트로 실효성 검증
> - 운영팀과의 워크플로우 통합
> - 이의제기 프로세스 구축
>
> 이 필요합니다.

### Q3: False Positive는 어떻게 처리하나요?

> **단계적 대응 전략**으로 해결합니다.
>
> 1. 모델이 어뷰징으로 판정해도 **즉시 차단하지 않습니다**
> 2. 먼저 **경고**를 보내고 **모니터링**합니다
> 3. 지속적 의심 행위가 확인되면 **심층 조사**합니다
> 4. 최종 확인 후에만 조치합니다
>
> 또한 **이의제기 채널**을 열어두어 억울한 판매자가 소명할 수 있게 합니다.

### Q4: 리뷰 유사도 계산 비용이 높지 않나요?

> 네, O(n²) 복잡도라 대규모에서는 문제될 수 있습니다.
>
> 해결 방법으로:
> - **샘플링**: 최근 100개 리뷰만 사용
> - **LSH (Locality Sensitive Hashing)**: 근사 유사도로 계산 가속
> - **배치 처리**: 실시간이 아닌 야간 배치로 계산
>
> 실제로 저는 max_features=100으로 TF-IDF를 제한하여 계산량을 줄였습니다.

### Q5: 어뷰징 판매자가 모델을 속일 수 있지 않나요?

> 맞습니다. 이것이 **적대적 환경(Adversarial Environment)**의 특성입니다.
>
> 대응 방안:
> - **정기적 재학습**: 새로운 패턴 반영
> - **피처 다변화**: 한두 가지 조작으로 회피 불가하게
> - **앙상블**: 여러 모델 조합으로 단일 취약점 방지
> - **이상 탐지**: 급격한 행동 변화 모니터링
>
> 궁극적으로는 **고양이와 쥐 게임**입니다. 지속적 개선이 필요합니다.

---

## 발표 체크리스트

- [ ] 노트북/데모 화면 준비
- [ ] Streamlit 앱 실행 확인
- [ ] 백업 슬라이드 (인터넷 안될 경우)
- [ ] SHAP Waterfall 차트 캡처
- [ ] Confusion Matrix, ROC Curve 이미지
- [ ] 시간 리허설 (15-20분)

---

**발표자료 생성일**: 2025년 1월 29일
