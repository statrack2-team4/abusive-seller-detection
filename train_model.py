import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
import shap

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score
from lightgbm import LGBMClassifier

# =============================================================================
# Mac í•œê¸€ í°íŠ¸ (í™•ì • ê²½ë¡œ)
# =============================================================================
font_path = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"
font_prop = fm.FontProperties(fname=font_path)
plt.rcParams["font.family"] = font_prop.get_name()
plt.rcParams["axes.unicode_minus"] = False

print(f"âœ… ì‚¬ìš© í°íŠ¸: {font_path}")

# =============================================================================
# Feature ì´ë¦„ í•œê¸€ ë§¤í•‘ (create_dashboard.pyì™€ ë™ì¼)
# =============================================================================
feature_names_kr = {
    'refund_question_ratio': 'í™˜ë¶ˆ ë¬¸ì˜ ë¹„ìœ¨',
    'rating_sentiment_gap': 'í‰ì -ê°ì„± ê´´ë¦¬ë„',
    'question_review_ratio': 'ë¬¸ì˜/ë¦¬ë·° ë¹„ìœ¨',
    'defect_question_ratio': 'ë¶ˆëŸ‰ ë¬¸ì˜ ë¹„ìœ¨',
    'negative_keyword_ratio': 'ë¶€ì • í‚¤ì›Œë“œ ë¹„ìœ¨',
    'avg_review_length': 'í‰ê·  ë¦¬ë·° ê¸¸ì´',
    'review_count': 'ë¦¬ë·° ê°œìˆ˜',
    'negative_sentiment_ratio': 'ë¶€ì • ê°ì„± ë¹„ìœ¨',
    'review_density': 'ë¦¬ë·° ë°€ë„',
    'textless_5star_ratio': 'í…ìŠ¤íŠ¸ ì—†ëŠ” 5ì  ë¹„ìœ¨',
    'question_density': 'ë¬¸ì˜ ë°€ë„',
    'avg_rating': 'í‰ê·  í‰ì ',
    'rating_std': 'í‰ì  í‘œì¤€í¸ì°¨',
    'low_rating_ratio': 'ì €í‰ì  ë¹„ìœ¨',
    'duplicate_review_ratio': 'ì¤‘ë³µ ë¦¬ë·° ë¹„ìœ¨',
    'question_count': 'ë¬¸ì˜ ê°œìˆ˜',
    'authenticity_question_ratio': 'ì§„í’ˆ ë¬¸ì˜ ë¹„ìœ¨',
    'avg_sentiment_score': 'í‰ê·  ê°ì„± ì ìˆ˜',
    'rating_normalized': 'ì •ê·œí™” í‰ì ',
    'product_count': 'ìƒí’ˆ ê°œìˆ˜',
    'conditions_met_count': 'ì¡°ê±´ ì¶©ì¡± ê°œìˆ˜'
}

# =============================================================================
# ì¶œë ¥ í´ë”
# =============================================================================
os.makedirs("output", exist_ok=True)

# =============================================================================
# ë°ì´í„° ë¡œë“œ
# =============================================================================
df = pd.read_csv("output/seller_features.csv")
df["label_name"] = df["abusive_label"].map({0: "ì •ìƒ", 1: "ì•…ì„±"})

# ëª¨ë¸ ì…ë ¥ (ë¬¸ìì—´ ì»¬ëŸ¼ ì œê±°)
drop_cols = ["vendor_name", "label_name"]
X = df.drop(columns=["abusive_label"] + drop_cols)
y = df["abusive_label"]

# =============================================================================
# í•™ìŠµ / í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
# =============================================================================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# =============================================================================
# ëª¨ë¸ í•™ìŠµ
# =============================================================================
model = LGBMClassifier(
    n_estimators=300,
    learning_rate=0.05,
    random_state=42
)
model.fit(X_train, y_train)

# =============================================================================
# ì˜ˆì¸¡
# =============================================================================
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

print("\nğŸ“Š ë¶„ë¥˜ ë¦¬í¬íŠ¸")
print(classification_report(y_test, y_pred, target_names=["ì •ìƒ", "ì•…ì„±"]))

# =============================================================================
# Feature Importance ì €ì¥
# =============================================================================
feature_importance = pd.DataFrame({
    "feature": X.columns,
    "feature_kr": [feature_names_kr.get(f, f) for f in X.columns],
    "importance": model.feature_importances_
}).sort_values(by="importance", ascending=False)

feature_importance.to_csv("output/feature_importance.csv", index=False)

# =============================================================================
# 05. í˜¼ë™ í–‰ë ¬
# =============================================================================
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(6, 5))
sns.heatmap(
    cm, annot=True, fmt="d", cmap="Blues",
    xticklabels=["ì˜ˆì¸¡: ì •ìƒ", "ì˜ˆì¸¡: ì•…ì„±"],
    yticklabels=["ì‹¤ì œ: ì •ìƒ", "ì‹¤ì œ: ì•…ì„±"]
)
plt.title("í˜¼ë™ í–‰ë ¬")
plt.xlabel("ì˜ˆì¸¡ê°’")
plt.ylabel("ì‹¤ì œê°’")
plt.tight_layout()
plt.savefig("output/05_í˜¼ë™í–‰ë ¬.png", dpi=300)
plt.close()

# =============================================================================
# 06. ROC ê³¡ì„ 
# =============================================================================
fpr, tpr, _ = roc_curve(y_test, y_prob)
auc = roc_auc_score(y_test, y_prob)

plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {auc:.3f}")
plt.plot([0, 1], [0, 1], linestyle="--")
plt.title("ROC ê³¡ì„ ")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.tight_layout()
plt.savefig("output/06_ROCê³¡ì„ .png", dpi=300)
plt.close()

# =============================================================================
# 07. íŠ¹ì„± ì¤‘ìš”ë„
# =============================================================================
top20 = feature_importance.head(20).iloc[::-1]

plt.figure(figsize=(8, 10))
plt.barh(top20["feature_kr"], top20["importance"])
plt.title("íŠ¹ì„± ì¤‘ìš”ë„")
plt.xlabel("ì¤‘ìš”ë„")
plt.ylabel("íŠ¹ì„±")
plt.tight_layout()
plt.savefig("output/07_íŠ¹ì„±ì¤‘ìš”ë„.png", dpi=300)
plt.close()

# =============================================================================
# 08. SHAP ìš”ì•½
# =============================================================================
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_train)

if isinstance(shap_values, list):
    shap_values_to_plot = shap_values[1]
else:
    shap_values_to_plot = shap_values

X_train_kr = X_train.copy()
X_train_kr.columns = [feature_names_kr.get(c, c) for c in X_train.columns]

plt.figure()
shap.summary_plot(shap_values_to_plot, X_train_kr, show=False)
plt.title("SHAP ìš”ì•½ ê·¸ë˜í”„")
plt.tight_layout()
plt.savefig("output/08_SHAPìš”ì•½.png", dpi=300)
plt.close()

# =============================================================================
# ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ (ëŒ€ì‹œë³´ë“œìš©)
# =============================================================================
predictions = pd.DataFrame({
    "actual": y_test.values,
    "predicted": y_pred,
    "probability": y_prob
})
predictions.to_csv("output/prediction_results.csv", index=False)

print("\nâœ… í•™ìŠµ ë° ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ")
print("ğŸ“ ìƒì„± íŒŒì¼:")
print(" - output/05_í˜¼ë™í–‰ë ¬.png")
print(" - output/06_ROCê³¡ì„ .png")
print(" - output/07_íŠ¹ì„±ì¤‘ìš”ë„.png")
print(" - output/08_SHAPìš”ì•½.png")
print(" - output/feature_importance.csv")
print(" - output/prediction_results.csv")
