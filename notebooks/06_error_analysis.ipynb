{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 에러 분석 (Error Analysis)\n",
    "\n",
    "학습된 최적 모델(Tuned Model)의 예측 결과를 분석합니다.\n",
    "\n",
    "Test Set에서의 오분류(False Positive, False Negative) 사례를 상세히 뜯어보고,\n",
    "\n",
    "모델이 왜 틀렸는지(SHAP), 어떤 패턴의 판매자를 놓치고 있는지 파악하여 개선 아이디어를 도출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import shap\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.features.feature_generation import FeatureGenerator, FEATURE_NAMES_KO, get_feature_name_ko\n",
    "from src.visualize import plot_shap_waterfall\n",
    "\n",
    "# 시각화 설정\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 및 전처리\n",
    "학습 때와 동일한 방식으로 피처 엔지니어링을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 로드 및 피처 생성\n",
    "generator = FeatureGenerator().load_data(from_db=True)\n",
    "features_df = generator.generate_all_features()\n",
    "\n",
    "# 타겟 및 피처 정의 (동적으로 피처 컬럼 추출)\n",
    "exclude_cols = ['company_name', 'is_abusing_seller']\n",
    "feature_columns = [col for col in features_df.columns if col not in exclude_cols]\n",
    "\n",
    "X = features_df[feature_columns]\n",
    "y = features_df['is_abusing_seller'].astype(int)\n",
    "\n",
    "print(f\"데이터 준비 완료: {features_df.shape}\")\n",
    "print(f\"총 피처 수: {len(feature_columns)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 및 스케일러 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델 찾기\n",
    "model_files = glob.glob('../models/abusing_detector_tuned_*.pkl')\n",
    "if not model_files:\n",
    "    raise FileNotFoundError(\"모델 파일을 찾을 수 없습니다. 05_model_improvement.ipynb를 먼저 실행해주세요.\")\n",
    "\n",
    "# 가장 최근 파일 사용\n",
    "latest_model_path = max(model_files, key=os.path.getctime)\n",
    "print(f\"로드할 모델: {latest_model_path}\")\n",
    "\n",
    "model = joblib.load(latest_model_path)\n",
    "scaler = joblib.load('../models/scaler_tuned.pkl')\n",
    "print(\"모델 및 스케일러 로드 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Set 예측 및 평가\n",
    "학습 때와 동일한 random_state(42)로 분리하여 Test Set을 확보합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 모델 타입 확인 후 스케일링 여부 결정\n",
    "model_type = str(type(model).__name__)\n",
    "print(f\"모델 타입: {model_type}\")\n",
    "\n",
    "# 트리 기반 모델은 스케일링 불필요\n",
    "tree_based_models = ['RandomForest', 'GradientBoosting', 'XGB', 'LGBM', 'ExtraTrees', 'DecisionTree', 'AdaBoost']\n",
    "needs_scaling = not any(tb in model_type for tb in tree_based_models)\n",
    "\n",
    "if needs_scaling:\n",
    "    print(\"→ 스케일링 필요 모델: 스케일링 적용\")\n",
    "    X_test_eval = scaler.transform(X_test)\n",
    "else:\n",
    "    print(\"→ 트리 기반 모델: 스케일링 없이 원본 데이터 사용\")\n",
    "    X_test_eval = X_test\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test_eval)\n",
    "y_proba = model.predict_proba(X_test_eval)[:, 1]\n",
    "\n",
    "# 평가 결과\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 오분류(Error) 분석\n",
    "\n",
    "Confusion Matrix를 통해 오분류 유형을 파악합니다.\n",
    "- **FP (False Positive)**: 정상 판매자를 어뷰징으로 오인 (억울한 판매자 발생)\n",
    "- **FN (False Negative)**: 어뷰징 판매자를 정상으로 오인 (탐지 실패)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix 시각화\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = ['정상 (0)', '어뷰징 (1)']\n",
    "\n",
    "fig = px.imshow(cm, text_auto=True, \n",
    "                x=labels, y=labels,\n",
    "                labels=dict(x=\"예측 결과\", y=\"실제 값\", color=\"빈도 수\"),\n",
    "                color_continuous_scale=\"Blues\")\n",
    "fig.update_layout(title=\"혼동 행렬 (Confusion Matrix)\", width=600, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석용 데이터프레임 생성\n",
    "analysis_df = X_test.copy()\n",
    "analysis_df['company_name'] = features_df.loc[X_test.index, 'company_name']\n",
    "analysis_df['actual'] = y_test\n",
    "analysis_df['predicted'] = y_pred\n",
    "analysis_df['prob_abusing'] = y_proba\n",
    "\n",
    "# 에러 유형 정의\n",
    "analysis_df['error_type'] = '정상 탐지 (Correct)'\n",
    "analysis_df.loc[(analysis_df['actual'] == 0) & (analysis_df['predicted'] == 1), 'error_type'] = '오탐 (False Positive)' # 정상인데 어뷰징이라 예측\n",
    "analysis_df.loc[(analysis_df['actual'] == 1) & (analysis_df['predicted'] == 0), 'error_type'] = '미탐 (False Negative)' # 어뷰징인데 정상이라 예측\n",
    "\n",
    "print(\"에러 유형 분포:\")\n",
    "print(analysis_df['error_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 False Positive 분석 (정상 -> 어뷰징 오탐)\n",
    "정상적인 판매자인데 왜 어뷰징으로 의심받았을까요? 특징을 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df = analysis_df[analysis_df['error_type'] == '오탐 (False Positive)'].sort_values('prob_abusing', ascending=False)\n",
    "\n",
    "# 표시할 주요 피처 (존재하는 것만)\n",
    "display_cols = ['company_name', 'actual', 'predicted', 'prob_abusing']\n",
    "optional_cols = ['satisfaction_score', 'review_count', 'avg_review_length', 'avg_rating', 'answer_rate']\n",
    "display_cols.extend([c for c in optional_cols if c in analysis_df.columns])\n",
    "\n",
    "print(f\"총 {len(fp_df)}건의 False Positive 발견\")\n",
    "if len(fp_df) > 0:\n",
    "    display(fp_df[display_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP 사례에 대한 SHAP 분석 (가장 확신을 가지고 틀린 케이스)\n",
    "if len(fp_df) > 0:\n",
    "    target_idx = fp_df.index[0]\n",
    "    target_row_loc = list(X_test.index).index(target_idx)\n",
    "    \n",
    "    print(f\"CASE: {fp_df.iloc[0]['company_name']} (Prob: {fp_df.iloc[0]['prob_abusing']:.4f})\")\n",
    "    \n",
    "    # TreeExplainer 지원 모델 (AdaBoost는 미지원)\n",
    "    tree_explainer_models = ['RandomForest', 'GradientBoosting', 'XGB', 'LGBM', 'ExtraTrees', 'DecisionTree']\n",
    "    use_tree_explainer = any(tm in str(type(model)) for tm in tree_explainer_models)\n",
    "    \n",
    "    if use_tree_explainer:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test_eval)\n",
    "        \n",
    "        # SHAP 값 추출 (Class 1에 대한 값)\n",
    "        if isinstance(shap_values, list):\n",
    "            sv = shap_values[1][target_row_loc]\n",
    "        elif hasattr(shap_values, 'shape') and len(shap_values.shape) == 3:\n",
    "            sv = shap_values[target_row_loc, :, 1]\n",
    "        else:\n",
    "            sv = shap_values[target_row_loc]\n",
    "\n",
    "        # Base Value 추출\n",
    "        if isinstance(explainer.expected_value, list):\n",
    "            bv = explainer.expected_value[1]\n",
    "        elif hasattr(explainer.expected_value, '__iter__') and len(explainer.expected_value) > 1:\n",
    "            bv = explainer.expected_value[1]\n",
    "        else:\n",
    "            bv = explainer.expected_value\n",
    "        \n",
    "        # Plotly Waterfall 시각화\n",
    "        fig = plot_shap_waterfall(\n",
    "            shap_values=sv,\n",
    "            sample_idx=target_row_loc,\n",
    "            feature_columns=feature_columns,\n",
    "            feature_values=X_test.iloc[target_row_loc],\n",
    "            base_value=bv,\n",
    "            top_n=20,\n",
    "            title=f\"<b>오탐 (False Positive): {fp_df.iloc[0]['company_name']}</b><br>Base: {float(bv[0]) if hasattr(bv, \"__len__\") else float(bv):.3f} → Prediction: {float((bv + sv.sum())[0]) if hasattr(bv + sv.sum(), \"__len__\") else float(bv + sv.sum()):.3f}\"\n",
    "        )\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"TreeExplainer 미지원 모델 - KernelExplainer로 대체\")\n",
    "        background = shap.sample(X_test, 50)\n",
    "        explainer = shap.KernelExplainer(model.predict_proba, background)\n",
    "        shap_values = explainer.shap_values(X_test_eval[target_row_loc:target_row_loc+1])\n",
    "        \n",
    "        if isinstance(shap_values, list):\n",
    "            sv = shap_values[1][0]\n",
    "        else:\n",
    "            sv = shap_values[0]\n",
    "        \n",
    "        bv = explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value\n",
    "        \n",
    "        fig = plot_shap_waterfall(\n",
    "            shap_values=sv,\n",
    "            sample_idx=target_row_loc,\n",
    "            feature_columns=feature_columns,\n",
    "            feature_values=X_test.iloc[target_row_loc],\n",
    "            base_value=bv,\n",
    "            top_n=20,\n",
    "            title=f\"<b>오탐 (False Positive): {fp_df.iloc[0]['company_name']}</b><br>Base: {float(bv[0]) if hasattr(bv, \"__len__\") else float(bv):.3f} → Prediction: {float((bv + sv.sum())[0]) if hasattr(bv + sv.sum(), \"__len__\") else float(bv + sv.sum()):.3f}\"\n",
    "        )\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 False Negative 분석 (어뷰징 -> 정상 미탐)\n",
    "어뷰징 판매자임에도 불구하고 왜 정상으로 판단했을까요? (가장 위험한 케이스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_df = analysis_df[analysis_df['error_type'] == '미탐 (False Negative)'].sort_values('prob_abusing')\n",
    "\n",
    "# 표시할 주요 피처 (존재하는 것만)\n",
    "display_cols = ['company_name', 'actual', 'predicted', 'prob_abusing']\n",
    "optional_cols = ['satisfaction_score', 'review_count', 'avg_review_length', 'avg_rating', 'answer_rate']\n",
    "display_cols.extend([c for c in optional_cols if c in analysis_df.columns])\n",
    "\n",
    "print(f\"총 {len(fn_df)}건의 False Negative 발견\")\n",
    "if len(fn_df) > 0:\n",
    "    display(fn_df[display_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FN 사례에 대한 SHAP 분석\n",
    "if len(fn_df) > 0:\n",
    "    target_idx = fn_df.index[0]\n",
    "    target_row_loc = list(X_test.index).index(target_idx)\n",
    "    \n",
    "    print(f\"CASE: {fn_df.iloc[0]['company_name']} (Prob: {fn_df.iloc[0]['prob_abusing']:.4f})\")\n",
    "    \n",
    "    # TreeExplainer 지원 모델 (AdaBoost는 미지원)\n",
    "    tree_explainer_models = ['RandomForest', 'GradientBoosting', 'XGB', 'LGBM', 'ExtraTrees', 'DecisionTree']\n",
    "    use_tree_explainer = any(tm in str(type(model)) for tm in tree_explainer_models)\n",
    "    \n",
    "    if use_tree_explainer:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test_eval)\n",
    "        \n",
    "        # SHAP 값 추출 (Class 1에 대한 값)\n",
    "        if isinstance(shap_values, list):\n",
    "            sv = shap_values[1][target_row_loc]\n",
    "        elif hasattr(shap_values, 'shape') and len(shap_values.shape) == 3:\n",
    "            sv = shap_values[target_row_loc, :, 1]\n",
    "        else:\n",
    "            sv = shap_values[target_row_loc]\n",
    "\n",
    "        # Base Value 추출\n",
    "        if isinstance(explainer.expected_value, list):\n",
    "            bv = explainer.expected_value[1]\n",
    "        elif hasattr(explainer.expected_value, '__iter__') and len(explainer.expected_value) > 1:\n",
    "            bv = explainer.expected_value[1]\n",
    "        else:\n",
    "            bv = explainer.expected_value\n",
    "        \n",
    "        # Plotly Waterfall 시각화\n",
    "        fig = plot_shap_waterfall(\n",
    "            shap_values=sv,\n",
    "            sample_idx=target_row_loc,\n",
    "            feature_columns=feature_columns,\n",
    "            feature_values=X_test.iloc[target_row_loc],\n",
    "            base_value=bv,\n",
    "            top_n=20,\n",
    "            title=f\"<b>미탐 (False Negative): {fn_df.iloc[0]['company_name']}</b><br>Base: {float(bv[0]) if hasattr(bv, \"__len__\") else float(bv):.3f} → Prediction: {float((bv + sv.sum())[0]) if hasattr(bv + sv.sum(), \"__len__\") else float(bv + sv.sum()):.3f}\"\n",
    "        )\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"TreeExplainer 미지원 모델 - KernelExplainer로 대체\")\n",
    "        background = shap.sample(X_test, 50)\n",
    "        explainer = shap.KernelExplainer(model.predict_proba, background)\n",
    "        shap_values = explainer.shap_values(X_test_eval[target_row_loc:target_row_loc+1])\n",
    "        \n",
    "        if isinstance(shap_values, list):\n",
    "            sv = shap_values[1][0]\n",
    "        else:\n",
    "            sv = shap_values[0]\n",
    "        \n",
    "        bv = explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value\n",
    "        \n",
    "        fig = plot_shap_waterfall(\n",
    "            shap_values=sv,\n",
    "            sample_idx=target_row_loc,\n",
    "            feature_columns=feature_columns,\n",
    "            feature_values=X_test.iloc[target_row_loc],\n",
    "            base_value=bv,\n",
    "            top_n=20,\n",
    "            title=f\"<b>미탐 (False Negative): {fn_df.iloc[0]['company_name']}</b><br>Base: {float(bv[0]) if hasattr(bv, \"__len__\") else float(bv):.3f} → Prediction: {float((bv + sv.sum())[0]) if hasattr(bv + sv.sum(), \"__len__\") else float(bv + sv.sum()):.3f}\"\n",
    "        )\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 에러 유형별 피처 분포 비교\n",
    "정상(TN), 어뷰징(TP) 그리고 에러(FP, FN) 그룹 간에 피처 분포 차이를 확인합니다.\n",
    "어떤 피처가 모델을 헷갈리게 만들었는지 직관적으로 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 피처 선정 (새 피처 세트에 맞게 업데이트)\n",
    "key_features = ['satisfaction_score', 'review_count', 'price', 'avg_review_length', 'answer_rate', \n",
    "                'negative_keyword_ratio', 'duplicate_review_ratio']\n",
    "\n",
    "# 존재하는 피처만 필터링\n",
    "key_features = [f for f in key_features if f in feature_columns]\n",
    "\n",
    "for col in key_features:\n",
    "    col_ko = get_feature_name_ko(col)\n",
    "    fig = px.box(analysis_df, x='error_type', y=col, color='error_type', \n",
    "                 title=f'{col_ko} 분포 (에러 유형별)',\n",
    "                 points=\"all\")\n",
    "    fig.update_layout(yaxis_title=col_ko)\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
