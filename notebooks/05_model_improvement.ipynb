{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어뷰징 탐지 모델 개선\n",
    "\n",
    "기존 모델의 과적합 문제를 해결하고, 더 robust한 모델을 개발합니다.\n",
    "\n",
    "## 개선 항목\n",
    "1. K-Fold 교차검증으로 모델 안정성 검증\n",
    "2. **Feature Selection으로 불필요한 피처 제거**\n",
    "3. 하이퍼파라미터 튜닝 (GridSearchCV)\n",
    "4. **Early Stopping으로 과적합 방지**\n",
    "5. 앙상블 기법 (Voting, Stacking)\n",
    "6. 클래스 불균형 처리\n",
    "7. **Learning Curve로 과적합 진단**\n",
    "8. SHAP 분석으로 모델 해석성 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    learning_curve,  # 과적합 진단용\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel, RFE  # Feature Selection\n",
    "from src.database import load_table\n",
    "from src.features.feature_generation import FeatureGenerator\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"라이브러리 로드 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers_df = load_table('sellers')\n",
    "products_df = load_table('products')\n",
    "reviews_df = load_table('reviews')\n",
    "questions_df = load_table('questions')\n",
    "\n",
    "print(f\"판매자: {len(sellers_df)}개\")\n",
    "print(f\"상품: {len(products_df)}개\")\n",
    "print(f\"리뷰: {len(reviews_df)}개\")\n",
    "print(f\"질문: {len(questions_df)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 엔지니어링\n",
    "generator = FeatureGenerator(\n",
    "    sellers_df=sellers_df,\n",
    "    products_df=products_df,\n",
    "    reviews_df=reviews_df,\n",
    "    questions_df=questions_df\n",
    ")\n",
    "features_df = generator.generate_legacy_features()\n",
    "\n",
    "print(f\"피처 데이터: {features_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처와 타겟 분리\n",
    "feature_columns = [\n",
    "    'satisfaction_score', 'review_count', 'total_product_count',\n",
    "    'product_count_actual', 'price_mean', 'price_std', 'price_min', 'price_max',\n",
    "    'rating_mean', 'rating_std', 'review_sum', 'review_mean',\n",
    "    'discount_mean', 'discount_max', 'shipping_fee_mean', 'shipping_days_mean',\n",
    "    'review_count_actual', 'review_rating_mean', 'review_rating_std',\n",
    "    'review_length_mean', 'review_length_std', 'review_length_max',\n",
    "    'question_count', 'answer_rate'\n",
    "]\n",
    "\n",
    "X = features_df[feature_columns]\n",
    "y = features_df['is_abusing_seller'].astype(int)\n",
    "\n",
    "# Train/Test 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"훈련 세트: {X_train.shape[0]}개 (어뷰징: {y_train.sum()}개, {y_train.mean()*100:.1f}%)\")\n",
    "print(f\"테스트 세트: {X_test.shape[0]}개 (어뷰징: {y_test.sum()}개, {y_test.mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Fold 교차검증으로 과적합 검증\n",
    "\n",
    "기존 Random Forest 100% 정확도가 과적합인지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold 교차검증\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "models_cv = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "print(\"5-Fold 교차검증 수행 중...\\n\")\n",
    "for name, model in models_cv.items():\n",
    "    # 스케일링이 필요한 모델\n",
    "    if name in ['Logistic Regression', 'SVM', 'KNN']:\n",
    "        X_cv = X_train_scaled\n",
    "    else:\n",
    "        X_cv = X_train\n",
    "    \n",
    "    # 여러 메트릭으로 교차검증\n",
    "    acc_scores = cross_val_score(model, X_cv, y_train, cv=cv, scoring='accuracy')\n",
    "    f1_scores = cross_val_score(model, X_cv, y_train, cv=cv, scoring='f1')\n",
    "    roc_scores = cross_val_score(model, X_cv, y_train, cv=cv, scoring='roc_auc')\n",
    "    \n",
    "    cv_results.append({\n",
    "        'model': name,\n",
    "        'acc_mean': acc_scores.mean(),\n",
    "        'acc_std': acc_scores.std(),\n",
    "        'f1_mean': f1_scores.mean(),\n",
    "        'f1_std': f1_scores.std(),\n",
    "        'roc_mean': roc_scores.mean(),\n",
    "        'roc_std': roc_scores.std()\n",
    "    })\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Accuracy: {acc_scores.mean():.4f} (+/- {acc_scores.std():.4f})\")\n",
    "    print(f\"  F1-Score: {f1_scores.mean():.4f} (+/- {f1_scores.std():.4f})\")\n",
    "    print(f\"  ROC-AUC:  {roc_scores.mean():.4f} (+/- {roc_scores.std():.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차검증 결과 시각화\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=('Accuracy', 'F1-Score', 'ROC-AUC'))\n",
    "\n",
    "colors = px.colors.qualitative.Set2\n",
    "\n",
    "for i, (metric, title) in enumerate([('acc', 'Accuracy'), ('f1', 'F1-Score'), ('roc', 'ROC-AUC')], 1):\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=cv_df['model'],\n",
    "            y=cv_df[f'{metric}_mean'],\n",
    "            error_y=dict(type='data', array=cv_df[f'{metric}_std']),\n",
    "            marker_color=colors[:len(cv_df)],\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=i\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='5-Fold 교차검증 결과 (평균 ± 표준편차)',\n",
    "    height=400,\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Feature Selection (과적합 방지)\n",
    "\n",
    "불필요한 피처를 제거하여 모델의 일반화 성능을 높입니다.\n",
    "- 피처가 많으면 노이즈에 과적합될 위험이 증가\n",
    "- 중요 피처만 선택하여 모델 복잡도 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection: Random Forest 기반 중요도로 피처 선택\n",
    "print(\"=== Feature Selection (과적합 방지) ===\\n\")\n",
    "\n",
    "# 1. 초기 RF로 피처 중요도 계산\n",
    "rf_selector = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_selector.fit(X_train, y_train)\n",
    "\n",
    "# 피처 중요도 시각화\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_selector.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "fig = px.bar(feature_importance, x='importance', y='feature', orientation='h',\n",
    "             title='피처 중요도 (Random Forest)', height=600)\n",
    "fig.show()\n",
    "\n",
    "# 2. SelectFromModel로 중요 피처 선택 (평균 이상 중요도)\n",
    "selector = SelectFromModel(rf_selector, threshold='mean', prefit=True)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "selected_features = [f for f, s in zip(feature_columns, selector.get_support()) if s]\n",
    "print(f\"선택된 피처 ({len(selected_features)}개): {selected_features}\")\n",
    "print(f\"제거된 피처 ({len(feature_columns) - len(selected_features)}개)\")\n",
    "\n",
    "# 3. 선택된 피처로 CV 성능 비교\n",
    "rf_full = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_selected = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "\n",
    "cv_full = cross_val_score(rf_full, X_train, y_train, cv=cv, scoring='f1')\n",
    "cv_selected = cross_val_score(rf_selected, X_train_selected, y_train, cv=cv, scoring='f1')\n",
    "\n",
    "print(f\"\\n전체 피처 CV F1: {cv_full.mean():.4f} (+/- {cv_full.std():.4f})\")\n",
    "print(f\"선택 피처 CV F1: {cv_selected.mean():.4f} (+/- {cv_selected.std():.4f})\")\n",
    "\n",
    "# 성능이 크게 떨어지지 않으면 선택된 피처 사용\n",
    "USE_SELECTED_FEATURES = cv_selected.mean() >= cv_full.mean() - 0.02\n",
    "print(f\"\\n→ 선택된 피처 사용: {USE_SELECTED_FEATURES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 하이퍼파라미터 튜닝 (과적합 방지 강화)\n",
    "print(\"Random Forest 하이퍼파라미터 튜닝 중...\")\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7, 10],           # 더 얕은 트리 추가 (과적합 방지)\n",
    "    'min_samples_split': [5, 10, 20],     # 더 큰 값 추가 (과적합 방지)\n",
    "    'min_samples_leaf': [2, 4, 8],        # 더 큰 값 추가 (과적합 방지)\n",
    "    'max_features': ['sqrt', 'log2', 0.5], # 피처 샘플링 (dropout 효과)\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, oob_score=True),  # OOB score로 일반화 성능 확인\n",
    "    rf_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n최적 파라미터: {rf_grid.best_params_}\")\n",
    "print(f\"최고 CV F1-Score: {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# OOB Score 확인 (과적합 여부 판단)\n",
    "best_rf_temp = rf_grid.best_estimator_\n",
    "if hasattr(best_rf_temp, 'oob_score_'):\n",
    "    print(f\"OOB Score: {best_rf_temp.oob_score_:.4f}\")\n",
    "    gap = rf_grid.best_score_ - best_rf_temp.oob_score_\n",
    "    print(f\"CV - OOB Gap: {gap:.4f} {'(과적합 의심)' if gap > 0.05 else '(양호)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting 하이퍼파라미터 튜닝 (Early Stopping 포함)\n",
    "print(\"Gradient Boosting 하이퍼파라미터 튜닝 중...\")\n",
    "\n",
    "# Early Stopping을 위한 Validation Set 분리\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],       # 충분히 크게 (Early Stopping이 조절)\n",
    "    'learning_rate': [0.01, 0.05, 0.1],    # 작은 학습률 추가\n",
    "    'max_depth': [2, 3, 4, 5],             # 더 얕은 트리 추가\n",
    "    'min_samples_split': [5, 10, 20],\n",
    "    'min_samples_leaf': [2, 4, 8],\n",
    "    'subsample': [0.7, 0.8, 0.9],          # 더 낮은 샘플링 추가\n",
    "    'max_features': ['sqrt', 0.5]          # 피처 샘플링 추가\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    GradientBoostingClassifier(\n",
    "        random_state=42,\n",
    "        validation_fraction=0.15,          # Early Stopping용 validation\n",
    "        n_iter_no_change=10,               # 10회 개선 없으면 중단\n",
    "        tol=1e-4\n",
    "    ),\n",
    "    gb_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n최적 파라미터: {gb_grid.best_params_}\")\n",
    "print(f\"최고 CV F1-Score: {gb_grid.best_score_:.4f}\")\n",
    "\n",
    "# 실제 사용된 트리 수 확인 (Early Stopping 효과)\n",
    "best_gb_temp = gb_grid.best_estimator_\n",
    "print(f\"실제 사용 트리 수: {best_gb_temp.n_estimators_} / {best_gb_temp.n_estimators} (Early Stop 효과)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression 하이퍼파라미터 튜닝 (ElasticNet 추가)\n",
    "print(\"Logistic Regression 하이퍼파라미터 튜닝 중...\")\n",
    "\n",
    "lr_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],        # 더 강한 정규화 포함\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'], # ElasticNet 추가\n",
    "    'solver': ['saga'],                     # ElasticNet 지원 solver\n",
    "    'l1_ratio': [0.3, 0.5, 0.7],           # ElasticNet 비율\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(random_state=42, max_iter=2000),\n",
    "    lr_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\n최적 파라미터: {lr_grid.best_params_}\")\n",
    "print(f\"최고 CV F1-Score: {lr_grid.best_score_:.4f}\")\n",
    "\n",
    "# 계수 분석 (0에 가까운 계수 = 중요하지 않은 피처)\n",
    "best_lr_temp = lr_grid.best_estimator_\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'coefficient': np.abs(best_lr_temp.coef_[0])\n",
    "}).sort_values('coefficient', ascending=False)\n",
    "print(f\"\\n정규화로 제거된 피처 수: {(coef_df['coefficient'] < 0.01).sum()}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 앙상블 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝된 모델들로 앙상블 구성\n",
    "best_rf = rf_grid.best_estimator_\n",
    "best_gb = gb_grid.best_estimator_\n",
    "best_lr = lr_grid.best_estimator_\n",
    "\n",
    "# Voting Classifier (Soft Voting)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', best_rf),\n",
    "        ('gb', best_gb),\n",
    "        ('lr', LogisticRegression(**lr_grid.best_params_, random_state=42, max_iter=1000))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 스케일링된 데이터로 학습 (LR 때문에)\n",
    "# 주의: 실제로는 파이프라인을 사용해야 하지만, 여기서는 RF/GB가 스케일링에 민감하지 않아 간소화\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 교차검증\n",
    "voting_cv_scores = cross_val_score(voting_clf, X_train_scaled, y_train, cv=cv, scoring='f1')\n",
    "print(f\"Voting Classifier CV F1: {voting_cv_scores.mean():.4f} (+/- {voting_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(**rf_grid.best_params_, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(**gb_grid.best_params_, random_state=42)),\n",
    "        ('lr', LogisticRegression(**lr_grid.best_params_, random_state=42, max_iter=1000))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(random_state=42, max_iter=1000),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 교차검증\n",
    "stacking_cv_scores = cross_val_score(stacking_clf, X_train_scaled, y_train, cv=cv, scoring='f1')\n",
    "print(f\"Stacking Classifier CV F1: {stacking_cv_scores.mean():.4f} (+/- {stacking_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Learning Curve 분석 (과적합 진단)\n",
    "\n",
    "Learning Curve는 훈련 데이터 크기에 따른 성능 변화를 보여줍니다:\n",
    "- **Train Score >> Validation Score**: 과적합 (모델이 너무 복잡)\n",
    "- **Train Score ≈ Validation Score (둘 다 낮음)**: 과소적합 (모델이 너무 단순)\n",
    "- **Train Score ≈ Validation Score (둘 다 높음)**: 이상적인 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve 계산 및 시각화\n",
    "print(\"Learning Curve 분석 중...\")\n",
    "\n",
    "# 튜닝된 RF 모델로 Learning Curve 계산\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    best_rf, X_train, y_train,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 평균 및 표준편차 계산\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "# Plotly로 시각화\n",
    "fig = go.Figure()\n",
    "\n",
    "# Training Score\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=train_sizes, y=train_mean,\n",
    "    mode='lines+markers',\n",
    "    name='Training Score',\n",
    "    line=dict(color='blue'),\n",
    "    error_y=dict(type='data', array=train_std, visible=True)\n",
    "))\n",
    "\n",
    "# Validation Score\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=train_sizes, y=val_mean,\n",
    "    mode='lines+markers',\n",
    "    name='Validation Score',\n",
    "    line=dict(color='green'),\n",
    "    error_y=dict(type='data', array=val_std, visible=True)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Learning Curve (Tuned Random Forest)',\n",
    "    xaxis_title='Training Set Size',\n",
    "    yaxis_title='F1 Score',\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# 과적합 진단\n",
    "gap = train_mean[-1] - val_mean[-1]\n",
    "print(f\"\\n=== 과적합 진단 ===\")\n",
    "print(f\"최종 Training F1: {train_mean[-1]:.4f}\")\n",
    "print(f\"최종 Validation F1: {val_mean[-1]:.4f}\")\n",
    "print(f\"Train-Val Gap: {gap:.4f}\")\n",
    "\n",
    "if gap > 0.1:\n",
    "    print(\"⚠️ 과적합 가능성 높음 - 모델 복잡도를 줄이거나 정규화 강화 필요\")\n",
    "elif gap > 0.05:\n",
    "    print(\"⚡ 약간의 과적합 - 주의 필요\")\n",
    "else:\n",
    "    print(\"✅ 과적합 없음 - 모델이 잘 일반화됨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 최종 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델 테스트 세트 평가\n",
    "final_models = {\n",
    "    'Tuned RF': (best_rf, X_test),\n",
    "    'Tuned GB': (best_gb, X_test),\n",
    "    'Tuned LR': (best_lr, X_test_scaled),\n",
    "    'Voting': (voting_clf, X_test_scaled),\n",
    "    'Stacking': (stacking_clf, X_test_scaled)\n",
    "}\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for name, (model, X_eval) in final_models.items():\n",
    "    y_pred = model.predict(X_eval)\n",
    "    y_proba = model.predict_proba(X_eval)[:, 1]\n",
    "    \n",
    "    results = {\n",
    "        'model': name,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "    }\n",
    "    final_results.append(results)\n",
    "\n",
    "final_df = pd.DataFrame(final_results)\n",
    "print(\"=== 최종 모델 성능 비교 (테스트 세트) ===\")\n",
    "print(final_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 비교 시각화\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "metric_names = ['정확도', '정밀도', '재현율', 'F1-Score', 'ROC-AUC']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for _, row in final_df.iterrows():\n",
    "    fig.add_trace(go.Bar(\n",
    "        name=row['model'],\n",
    "        x=metric_names,\n",
    "        y=[row[m] for m in metrics]\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='튜닝된 모델 성능 비교 (테스트 세트)',\n",
    "    barmode='group',\n",
    "    yaxis_title='Score',\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve 비교\n",
    "fig = go.Figure()\n",
    "\n",
    "for name, (model, X_eval) in final_models.items():\n",
    "    y_proba = model.predict_proba(X_eval)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=fpr, y=tpr,\n",
    "        name=f'{name} (AUC={auc:.3f})',\n",
    "        mode='lines'\n",
    "    ))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1], y=[0, 1],\n",
    "    name='Random',\n",
    "    mode='lines',\n",
    "    line=dict(dash='dash', color='gray')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='튜닝된 모델 ROC Curve 비교',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SHAP 분석 (모델 해석성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP 설치 확인\n",
    "try:\n",
    "    import shap\n",
    "    print(f\"SHAP 버전: {shap.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"SHAP 설치 중...\")\n",
    "    !uv add shap\n",
    "    import shap\n",
    "    print(\"SHAP 설치 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 모델 선택 (F1 기준)\n",
    "best_model_name = final_df.loc[final_df['f1'].idxmax(), 'model']\n",
    "print(f\"SHAP 분석 대상 모델: {best_model_name}\")\n",
    "\n",
    "# TreeExplainer 사용 (RF, GB)\n",
    "if 'RF' in best_model_name:\n",
    "    explainer = shap.TreeExplainer(best_rf)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]  # 어뷰징 클래스\n",
    "elif 'GB' in best_model_name:\n",
    "    explainer = shap.TreeExplainer(best_gb)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "else:\n",
    "    # 다른 모델의 경우 KernelExplainer 사용\n",
    "    model, X_eval = final_models[best_model_name]\n",
    "    explainer = shap.KernelExplainer(model.predict_proba, shap.sample(X_train_scaled, 100))\n",
    "    shap_values = explainer.shap_values(X_eval[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Beeswarm Plot (피처 영향 방향) - Plotly 구현\n",
    "\n",
    "# shap_values가 3차원(samples, features, classes)이거나 리스트인 경우 처리\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values_2d = shap_values[1]  # Positive class\n",
    "elif hasattr(shap_values, 'shape') and len(shap_values.shape) == 3:\n",
    "    shap_values_2d = shap_values[:, :, 1]  # Positive class\n",
    "else:\n",
    "    shap_values_2d = shap_values\n",
    "\n",
    "# 데이터 준비\n",
    "shap_df = pd.DataFrame(shap_values_2d, columns=feature_columns)\n",
    "\n",
    "# 색상을 위해 스케일링된 데이터 사용 (각 피처별로 Low/High 구분 명확화)\n",
    "feature_df = pd.DataFrame(X_test_scaled, columns=feature_columns)\n",
    "\n",
    "# 시각화를 위해 데이터 변환 (Long Format)\n",
    "shap_melted = shap_df.melt(var_name='feature', value_name='shap_value')\n",
    "feature_melted = feature_df.melt(var_name='feature', value_name='feature_value')\n",
    "\n",
    "plot_df = shap_melted.copy()\n",
    "plot_df['feature_value'] = feature_melted['feature_value']\n",
    "\n",
    "# 중요도 순으로 정렬\n",
    "mean_abs_shap = np.abs(shap_values_2d).mean(axis=0)\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': mean_abs_shap\n",
    "}).sort_values('importance', ascending=True)\n",
    "sorted_features = importance_df['feature'].tolist()\n",
    "\n",
    "# Plotly Strip Plot\n",
    "fig = px.strip(\n",
    "    plot_df, \n",
    "    x='shap_value', \n",
    "    y='feature', \n",
    "    color='feature_value',\n",
    "    category_orders={'feature': sorted_features},\n",
    "    title='SHAP 피처 영향 분석 (Beeswarm Style)',\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='SHAP Value (impact on model output)',\n",
    "    yaxis_title='Feature',\n",
    "    coloraxis_colorscale='RdBu_r'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Summary Plot (피처 중요도) - Plotly 구현\n",
    "# 위에서 계산한 importance_df 사용\n",
    "\n",
    "fig = px.bar(\n",
    "    importance_df, \n",
    "    x='importance', \n",
    "    y='feature', \n",
    "    orientation='h',\n",
    "    title='SHAP 피처 중요도 (Mean Absolute SHAP Value)',\n",
    "    height=600\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title='mean(|SHAP value|)',\n",
    "    yaxis_title='Feature'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Waterfall 시각화 (src/visualize에서 함수 import)\n",
    "from src.visualize import plot_shap_waterfall\n",
    "\n",
    "# 첫 번째 어뷰징 샘플 시각화\n",
    "abusing_idx = y_test[y_test == 1].index[0]\n",
    "sample_idx = list(y_test.index).index(abusing_idx)\n",
    "\n",
    "# SHAP 값 추출 (Class 1에 대한 값)\n",
    "sv_class1 = shap_values[sample_idx][:, 1]\n",
    "base_value = explainer.expected_value[1]\n",
    "features = X_test.iloc[sample_idx]\n",
    "\n",
    "# Waterfall 차트 그리기\n",
    "fig = plot_shap_waterfall(\n",
    "    shap_values=sv_class1,\n",
    "    sample_idx=sample_idx,\n",
    "    feature_columns=feature_columns,\n",
    "    feature_values=features,\n",
    "    base_value=base_value,\n",
    "    top_n=20\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 최종 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최고 성능 모델 저장\n",
    "best_idx = final_df['f1'].idxmax()\n",
    "best_model_name = final_df.loc[best_idx, 'model']\n",
    "best_model_obj = final_models[best_model_name][0]\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# 모델 저장\n",
    "model_filename = f'abusing_detector_tuned_{best_model_name.lower().replace(\" \", \"_\")}.pkl'\n",
    "joblib.dump(best_model_obj, f'../models/{model_filename}')\n",
    "joblib.dump(scaler, '../models/scaler_tuned.pkl')\n",
    "\n",
    "# 튜닝 파라미터 저장\n",
    "tuning_results = {\n",
    "    'rf_params': rf_grid.best_params_,\n",
    "    'gb_params': gb_grid.best_params_,\n",
    "    'lr_params': lr_grid.best_params_,\n",
    "    'best_model': best_model_name,\n",
    "    'best_f1': final_df.loc[best_idx, 'f1'],\n",
    "    'cv_results': cv_results\n",
    "}\n",
    "joblib.dump(tuning_results, '../models/tuning_results.pkl')\n",
    "\n",
    "print(f\"최종 모델 저장 완료: models/{model_filename}\")\n",
    "print(f\"스케일러 저장 완료: models/scaler_tuned.pkl\")\n",
    "print(f\"튜닝 결과 저장 완료: models/tuning_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"어뷰징 탐지 모델 개선 완료\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[1] 과적합 방지 기법 적용\")\n",
    "print(\"-\" * 50)\n",
    "print(\"✓ Feature Selection: 중요 피처만 선택 (SelectFromModel)\")\n",
    "print(\"✓ max_features: 피처 샘플링으로 dropout 효과\")\n",
    "print(\"✓ Early Stopping: GB에서 validation loss 기반 조기 종료\")\n",
    "print(\"✓ 강한 정규화: max_depth 제한, min_samples 증가\")\n",
    "print(\"✓ ElasticNet: L1+L2 혼합 정규화\")\n",
    "print(\"✓ Learning Curve: Train-Val gap으로 과적합 진단\")\n",
    "print(\"✓ OOB Score: RF에서 out-of-bag 샘플로 일반화 성능 확인\")\n",
    "\n",
    "print(\"\\n[2] 교차검증 결과\")\n",
    "print(\"-\" * 50)\n",
    "cv_summary = pd.DataFrame(cv_results)[['model', 'f1_mean', 'f1_std']].sort_values('f1_mean', ascending=False)\n",
    "print(cv_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n[3] 하이퍼파라미터 튜닝 결과\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Random Forest 최적 파라미터:\")\n",
    "for k, v in rf_grid.best_params_.items():\n",
    "    print(f\"  - {k}: {v}\")\n",
    "print(f\"\\nGradient Boosting 최적 파라미터:\")\n",
    "for k, v in gb_grid.best_params_.items():\n",
    "    print(f\"  - {k}: {v}\")\n",
    "\n",
    "print(\"\\n[4] 최종 모델 성능 (테스트 세트)\")\n",
    "print(\"-\" * 50)\n",
    "print(final_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n[5] 최종 선택 모델: {best_model_name}\")\n",
    "print(f\"    F1-Score: {final_df.loc[best_idx, 'f1']:.4f}\")\n",
    "print(f\"    ROC-AUC: {final_df.loc[best_idx, 'roc_auc']:.4f}\")\n",
    "\n",
    "# Learning Curve 결과 요약\n",
    "print(f\"\\n[6] 과적합 진단 결과\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"    Train-Val Gap: {gap:.4f}\")\n",
    "if gap > 0.1:\n",
    "    print(\"    상태: ⚠️ 과적합 가능성 높음\")\n",
    "elif gap > 0.05:\n",
    "    print(\"    상태: ⚡ 약간의 과적합\")\n",
    "else:\n",
    "    print(\"    상태: ✅ 양호 (과적합 없음)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
