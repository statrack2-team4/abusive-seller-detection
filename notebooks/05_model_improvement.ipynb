{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어뷰징 탐지 모델 개선\n",
    "\n",
    "기존 모델의 과적합 문제를 해결하고, 더 robust한 모델을 개발합니다.\n",
    "\n",
    "## 개선 항목\n",
    "1. K-Fold 교차검증으로 모델 안정성 검증\n",
    "2. 하이퍼파라미터 튜닝 (GridSearchCV)\n",
    "3. 앙상블 기법 (Voting, Stacking)\n",
    "4. 클래스 불균형 처리\n",
    "5. SHAP 분석으로 모델 해석성 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, StratifiedKFold,\n",
    "    GridSearchCV\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    "    VotingClassifier, StackingClassifier, AdaBoostClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"라이브러리 로드 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.database.supabase_client import get_supabase_client\n",
    "\n",
    "client = get_supabase_client()\n",
    "\n",
    "def load_all_data(table_name):\n",
    "    response = client.table(table_name).select(\"*\").execute()\n",
    "    return pd.DataFrame(response.data)\n",
    "\n",
    "# 데이터 로드\n",
    "sellers_df = load_all_data('sellers')\n",
    "products_df = load_all_data('products')\n",
    "reviews_df = load_all_data('reviews')\n",
    "questions_df = load_all_data('questions')\n",
    "\n",
    "print(f\"판매자: {len(sellers_df)}개\")\n",
    "print(f\"상품: {len(products_df)}개\")\n",
    "print(f\"리뷰: {len(reviews_df)}개\")\n",
    "print(f\"질문: {len(questions_df)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 엔지니어링 (이전 노트북과 동일)\n",
    "product_vendor_map = products_df[['product_id', 'vendor_name']].drop_duplicates()\n",
    "\n",
    "# 판매자별 상품 통계\n",
    "product_stats = products_df.groupby('vendor_name').agg({\n",
    "    'product_id': 'count',\n",
    "    'price': ['mean', 'std', 'min', 'max'],\n",
    "    'product_rating': ['mean', 'std'],\n",
    "    'review_count': ['sum', 'mean'],\n",
    "    'discount_rate': ['mean', 'max'],\n",
    "    'shipping_fee': 'mean',\n",
    "    'shipping_days': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "product_stats.columns = [\n",
    "    'company_name', 'product_count_actual',\n",
    "    'price_mean', 'price_std', 'price_min', 'price_max',\n",
    "    'rating_mean', 'rating_std', 'review_sum', 'review_mean',\n",
    "    'discount_mean', 'discount_max', 'shipping_fee_mean', 'shipping_days_mean'\n",
    "]\n",
    "\n",
    "# 리뷰 통계\n",
    "reviews_with_vendor = reviews_df.merge(product_vendor_map, on='product_id', how='left')\n",
    "reviews_with_vendor['text_length'] = reviews_with_vendor['review_text'].apply(\n",
    "    lambda x: len(str(x)) if pd.notna(x) else 0\n",
    ")\n",
    "\n",
    "review_stats = reviews_with_vendor.groupby('vendor_name').agg({\n",
    "    'id': 'count',\n",
    "    'review_rating': ['mean', 'std'],\n",
    "    'text_length': ['mean', 'std', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "review_stats.columns = [\n",
    "    'company_name', 'review_count_actual',\n",
    "    'review_rating_mean', 'review_rating_std',\n",
    "    'review_length_mean', 'review_length_std', 'review_length_max'\n",
    "]\n",
    "\n",
    "# 질문 통계\n",
    "questions_with_vendor = questions_df.merge(product_vendor_map, on='product_id', how='left')\n",
    "questions_with_vendor['has_answer'] = questions_with_vendor['answer'].apply(\n",
    "    lambda x: 1 if pd.notna(x) and str(x).strip() != '' else 0\n",
    ")\n",
    "\n",
    "question_stats = questions_with_vendor.groupby('vendor_name').agg({\n",
    "    'id': 'count',\n",
    "    'has_answer': 'mean'\n",
    "}).reset_index()\n",
    "question_stats.columns = ['company_name', 'question_count', 'answer_rate']\n",
    "\n",
    "# 피처 병합\n",
    "features_df = sellers_df[[\n",
    "    'company_name', 'satisfaction_score', 'review_count',\n",
    "    'total_product_count', 'is_abusing_seller'\n",
    "]].copy()\n",
    "\n",
    "features_df = features_df.merge(product_stats, on='company_name', how='left')\n",
    "features_df = features_df.merge(review_stats, on='company_name', how='left')\n",
    "features_df = features_df.merge(question_stats, on='company_name', how='left')\n",
    "features_df = features_df.fillna(0)\n",
    "\n",
    "print(f\"피처 데이터: {features_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처와 타겟 분리\n",
    "feature_columns = [\n",
    "    'satisfaction_score', 'review_count', 'total_product_count',\n",
    "    'product_count_actual', 'price_mean', 'price_std', 'price_min', 'price_max',\n",
    "    'rating_mean', 'rating_std', 'review_sum', 'review_mean',\n",
    "    'discount_mean', 'discount_max', 'shipping_fee_mean', 'shipping_days_mean',\n",
    "    'review_count_actual', 'review_rating_mean', 'review_rating_std',\n",
    "    'review_length_mean', 'review_length_std', 'review_length_max',\n",
    "    'question_count', 'answer_rate'\n",
    "]\n",
    "\n",
    "X = features_df[feature_columns]\n",
    "y = features_df['is_abusing_seller'].astype(int)\n",
    "\n",
    "# Train/Test 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"훈련 세트: {X_train.shape[0]}개 (어뷰징: {y_train.sum()}개, {y_train.mean()*100:.1f}%)\")\n",
    "print(f\"테스트 세트: {X_test.shape[0]}개 (어뷰징: {y_test.sum()}개, {y_test.mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Fold 교차검증으로 과적합 검증\n",
    "\n",
    "기존 Random Forest 100% 정확도가 과적합인지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold 교차검증\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "models_cv = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "print(\"5-Fold 교차검증 수행 중...\\n\")\n",
    "for name, model in models_cv.items():\n",
    "    # 스케일링이 필요한 모델\n",
    "    if name in ['Logistic Regression', 'SVM', 'KNN']:\n",
    "        X_cv = X_train_scaled\n",
    "    else:\n",
    "        X_cv = X_train\n",
    "    \n",
    "    # 여러 메트릭으로 교차검증\n",
    "    acc_scores = cross_val_score(model, X_cv, y_train, cv=cv, scoring='accuracy')\n",
    "    f1_scores = cross_val_score(model, X_cv, y_train, cv=cv, scoring='f1')\n",
    "    roc_scores = cross_val_score(model, X_cv, y_train, cv=cv, scoring='roc_auc')\n",
    "    \n",
    "    cv_results.append({\n",
    "        'model': name,\n",
    "        'acc_mean': acc_scores.mean(),\n",
    "        'acc_std': acc_scores.std(),\n",
    "        'f1_mean': f1_scores.mean(),\n",
    "        'f1_std': f1_scores.std(),\n",
    "        'roc_mean': roc_scores.mean(),\n",
    "        'roc_std': roc_scores.std()\n",
    "    })\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Accuracy: {acc_scores.mean():.4f} (+/- {acc_scores.std():.4f})\")\n",
    "    print(f\"  F1-Score: {f1_scores.mean():.4f} (+/- {f1_scores.std():.4f})\")\n",
    "    print(f\"  ROC-AUC:  {roc_scores.mean():.4f} (+/- {roc_scores.std():.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차검증 결과 시각화\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=('Accuracy', 'F1-Score', 'ROC-AUC'))\n",
    "\n",
    "colors = px.colors.qualitative.Set2\n",
    "\n",
    "for i, (metric, title) in enumerate([('acc', 'Accuracy'), ('f1', 'F1-Score'), ('roc', 'ROC-AUC')], 1):\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=cv_df['model'],\n",
    "            y=cv_df[f'{metric}_mean'],\n",
    "            error_y=dict(type='data', array=cv_df[f'{metric}_std']),\n",
    "            marker_color=colors[:len(cv_df)],\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=i\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='5-Fold 교차검증 결과 (평균 ± 표준편차)',\n",
    "    height=400,\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 하이퍼파라미터 튜닝\n",
    "print(\"Random Forest 하이퍼파라미터 튜닝 중...\")\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n최적 파라미터: {rf_grid.best_params_}\")\n",
    "print(f\"최고 CV F1-Score: {rf_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting 하이퍼파라미터 튜닝\n",
    "print(\"Gradient Boosting 하이퍼파라미터 튜닝 중...\")\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    gb_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n최적 파라미터: {gb_grid.best_params_}\")\n",
    "print(f\"최고 CV F1-Score: {gb_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression 하이퍼파라미터 튜닝\n",
    "print(\"Logistic Regression 하이퍼파라미터 튜닝 중...\")\n",
    "\n",
    "lr_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    lr_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\n최적 파라미터: {lr_grid.best_params_}\")\n",
    "print(f\"최고 CV F1-Score: {lr_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 앙상블 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝된 모델들로 앙상블 구성\n",
    "best_rf = rf_grid.best_estimator_\n",
    "best_gb = gb_grid.best_estimator_\n",
    "best_lr = lr_grid.best_estimator_\n",
    "\n",
    "# Voting Classifier (Soft Voting)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', best_rf),\n",
    "        ('gb', best_gb),\n",
    "        ('lr', LogisticRegression(**lr_grid.best_params_, random_state=42, max_iter=1000))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 스케일링된 데이터로 학습 (LR 때문에)\n",
    "# 주의: 실제로는 파이프라인을 사용해야 하지만, 여기서는 RF/GB가 스케일링에 민감하지 않아 간소화\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 교차검증\n",
    "voting_cv_scores = cross_val_score(voting_clf, X_train_scaled, y_train, cv=cv, scoring='f1')\n",
    "print(f\"Voting Classifier CV F1: {voting_cv_scores.mean():.4f} (+/- {voting_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(**rf_grid.best_params_, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(**gb_grid.best_params_, random_state=42)),\n",
    "        ('lr', LogisticRegression(**lr_grid.best_params_, random_state=42, max_iter=1000))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(random_state=42, max_iter=1000),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 교차검증\n",
    "stacking_cv_scores = cross_val_score(stacking_clf, X_train_scaled, y_train, cv=cv, scoring='f1')\n",
    "print(f\"Stacking Classifier CV F1: {stacking_cv_scores.mean():.4f} (+/- {stacking_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 최종 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델 테스트 세트 평가\n",
    "final_models = {\n",
    "    'Tuned RF': (best_rf, X_test),\n",
    "    'Tuned GB': (best_gb, X_test),\n",
    "    'Tuned LR': (best_lr, X_test_scaled),\n",
    "    'Voting': (voting_clf, X_test_scaled),\n",
    "    'Stacking': (stacking_clf, X_test_scaled)\n",
    "}\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for name, (model, X_eval) in final_models.items():\n",
    "    y_pred = model.predict(X_eval)\n",
    "    y_proba = model.predict_proba(X_eval)[:, 1]\n",
    "    \n",
    "    results = {\n",
    "        'model': name,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "    }\n",
    "    final_results.append(results)\n",
    "\n",
    "final_df = pd.DataFrame(final_results)\n",
    "print(\"=== 최종 모델 성능 비교 (테스트 세트) ===\")\n",
    "print(final_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 비교 시각화\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "metric_names = ['정확도', '정밀도', '재현율', 'F1-Score', 'ROC-AUC']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for _, row in final_df.iterrows():\n",
    "    fig.add_trace(go.Bar(\n",
    "        name=row['model'],\n",
    "        x=metric_names,\n",
    "        y=[row[m] for m in metrics]\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='튜닝된 모델 성능 비교 (테스트 세트)',\n",
    "    barmode='group',\n",
    "    yaxis_title='Score',\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve 비교\n",
    "fig = go.Figure()\n",
    "\n",
    "for name, (model, X_eval) in final_models.items():\n",
    "    y_proba = model.predict_proba(X_eval)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=fpr, y=tpr,\n",
    "        name=f'{name} (AUC={auc:.3f})',\n",
    "        mode='lines'\n",
    "    ))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1], y=[0, 1],\n",
    "    name='Random',\n",
    "    mode='lines',\n",
    "    line=dict(dash='dash', color='gray')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='튜닝된 모델 ROC Curve 비교',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SHAP 분석 (모델 해석성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP 설치 확인\n",
    "try:\n",
    "    import shap\n",
    "    print(f\"SHAP 버전: {shap.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"SHAP 설치 중...\")\n",
    "    !uv add shap\n",
    "    import shap\n",
    "    print(\"SHAP 설치 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# 최적 모델 선택 (F1 기준)\n",
    "best_model_name = final_df.loc[final_df['f1'].idxmax(), 'model']\n",
    "print(f\"SHAP 분석 대상 모델: {best_model_name}\")\n",
    "\n",
    "# TreeExplainer 사용 (RF, GB)\n",
    "if 'RF' in best_model_name:\n",
    "    explainer = shap.TreeExplainer(best_rf)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]  # 어뷰징 클래스\n",
    "elif 'GB' in best_model_name:\n",
    "    explainer = shap.TreeExplainer(best_gb)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "else:\n",
    "    # 다른 모델의 경우 KernelExplainer 사용\n",
    "    model, X_eval = final_models[best_model_name]\n",
    "    explainer = shap.KernelExplainer(model.predict_proba, shap.sample(X_train_scaled, 100))\n",
    "    shap_values = explainer.shap_values(X_eval[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Beeswarm Plot (피처 영향 방향)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test, feature_names=feature_columns, show=False)\n",
    "plt.title('SHAP 피처 영향 분석')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Summary Plot (피처 중요도)\n",
    "shap.summary_plot(shap_values, X_test, feature_names=feature_columns, plot_type='bar', show=False)\n",
    "plt.title('SHAP 피처 중요도')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 예측 설명 (첫 번째 어뷰징 샘플)\n",
    "abusing_idx = y_test[y_test == 1].index[0]\n",
    "sample_idx = list(y_test.index).index(abusing_idx)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. 데이터 준비 (Class 1에 대한 값만 추출)\n",
    "# ---------------------------------------------------------\n",
    "# shap_values가 (samples, features, 2) 형태라고 가정\n",
    "sv_class1 = shap_values[sample_idx][:, 1]   # Class 1(어뷰징) SHAP 값\n",
    "base_value = explainer.expected_value[1]    # Base Value (평균 예측값)\n",
    "features = X_test.iloc[sample_idx]          # 해당 샘플의 실제 피처값\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. 시각화를 위해 중요도 순으로 정렬 (절대값 기준)\n",
    "# ---------------------------------------------------------\n",
    "df_shap = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'shap_value': sv_class1,\n",
    "    'feature_value': features.values\n",
    "})\n",
    "\n",
    "# SHAP 값의 절대값 크기순으로 정렬 (상위 20개만 보기 위해)\n",
    "df_shap['abs_shap'] = df_shap['shap_value'].abs()\n",
    "df_shap = df_shap.sort_values('abs_shap', ascending=True).tail(20) # 하위 20개(중요도 높은순)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Plotly Waterfall 그리기\n",
    "# ---------------------------------------------------------\n",
    "fig = go.Figure(go.Waterfall(\n",
    "    name = \"SHAP\",\n",
    "    orientation = \"h\",  # 가로 방향\n",
    "    measure = [\"relative\"] * len(df_shap),\n",
    "    y = df_shap['feature'],  # Y축: 피처 이름\n",
    "    x = df_shap['shap_value'], # X축: SHAP 기여도\n",
    "    text = df_shap['feature_value'].apply(lambda x: f\"{x:.2f}\" if isinstance(x, float) else str(x)), # 막대 옆에 실제 값 표시\n",
    "    textposition = \"outside\",\n",
    "    connector = {\"mode\":\"between\", \"line\":{\"width\":1, \"color\":\"rgb(150,150,150)\", \"dash\":\"dot\"}}\n",
    "))\n",
    "\n",
    "# 레이아웃 설정 (Base Value 표시 등)\n",
    "final_prob = base_value + df_shap['shap_value'].sum() # 근사치 (top 20개만 합쳤으므로)\n",
    "\n",
    "fig.update_layout(\n",
    "    title = {\n",
    "        'text': f\"<b>Sample #{sample_idx} 예측 설명 (Waterfall)</b><br>Base: {base_value:.3f} → Prediction: {base_value + sv_class1.sum():.3f}\",\n",
    "        'y':0.95, 'x':0.5, 'xanchor': 'center', 'yanchor': 'top'\n",
    "    },\n",
    "    showlegend = False,\n",
    "    height = 600, # 그래프 높이 조절\n",
    "    xaxis = dict(title = \"SHAP Value (기여도)\"),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 최종 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최고 성능 모델 저장\n",
    "best_idx = final_df['f1'].idxmax()\n",
    "best_model_name = final_df.loc[best_idx, 'model']\n",
    "best_model_obj = final_models[best_model_name][0]\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# 모델 저장\n",
    "model_filename = f'abusing_detector_tuned_{best_model_name.lower().replace(\" \", \"_\")}.pkl'\n",
    "joblib.dump(best_model_obj, f'../models/{model_filename}')\n",
    "joblib.dump(scaler, '../models/scaler_tuned.pkl')\n",
    "\n",
    "# 튜닝 파라미터 저장\n",
    "tuning_results = {\n",
    "    'rf_params': rf_grid.best_params_,\n",
    "    'gb_params': gb_grid.best_params_,\n",
    "    'lr_params': lr_grid.best_params_,\n",
    "    'best_model': best_model_name,\n",
    "    'best_f1': final_df.loc[best_idx, 'f1'],\n",
    "    'cv_results': cv_results\n",
    "}\n",
    "joblib.dump(tuning_results, '../models/tuning_results.pkl')\n",
    "\n",
    "print(f\"최종 모델 저장 완료: models/{model_filename}\")\n",
    "print(f\"스케일러 저장 완료: models/scaler_tuned.pkl\")\n",
    "print(f\"튜닝 결과 저장 완료: models/tuning_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"어뷰징 탐지 모델 개선 완료\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[1] 교차검증 결과\")\n",
    "print(\"-\" * 50)\n",
    "cv_summary = pd.DataFrame(cv_results)[['model', 'f1_mean', 'f1_std']].sort_values('f1_mean', ascending=False)\n",
    "print(cv_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n[2] 하이퍼파라미터 튜닝 결과\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Random Forest 최적 파라미터:\")\n",
    "for k, v in rf_grid.best_params_.items():\n",
    "    print(f\"  - {k}: {v}\")\n",
    "print(f\"\\nGradient Boosting 최적 파라미터:\")\n",
    "for k, v in gb_grid.best_params_.items():\n",
    "    print(f\"  - {k}: {v}\")\n",
    "\n",
    "print(\"\\n[3] 최종 모델 성능 (테스트 세트)\")\n",
    "print(\"-\" * 50)\n",
    "print(final_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n[4] 최종 선택 모델: {best_model_name}\")\n",
    "print(f\"    F1-Score: {final_df.loc[best_idx, 'f1']:.4f}\")\n",
    "print(f\"    ROC-AUC: {final_df.loc[best_idx, 'roc_auc']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
